# myAE â€“ Techstack & Architektur

## ğŸ“Œ Projektziel

myAE ist ein AI-gestÃ¼tztes Memory-System, das OpenAI GPT nutzt, um personalisierte tÃ¤gliche Nachrichten und intelligente Antworten zu liefern. Die Architektur ist serverless-first, optimiert fÃ¼r Vercel und auf Skalierbarkeit ausgelegt.

## 1ï¸âƒ£ Infrastruktur & Hosting

**Backend: Vercel**

Vercel wird als serverless Deployment-Umgebung genutzt, um das Projekt einfach und performant zu hosten.

### Vorteile:

- Automatisches Scaling, keine Serververwaltung
- Direkte GitHub-Integration fÃ¼r Continuous Deployment
- UnterstÃ¼tzt Next.js nativ (keine manuelle Konfiguration nÃ¶tig)

## 2ï¸âƒ£ Tech-Stack & Hauptkomponenten

### ğŸ”¹ Programmiersprache & Framework

- **Next.js (App Router, TypeScript)**
  - API-Endpoints liegen in `src/app/api/[route]/route.ts`
  - UnterstÃ¼tzt serverseitige Logik und Middleware direkt
- **TypeScript**
  - Statische Typisierung fÃ¼r sauberen Code und bessere Skalierbarkeit

### ğŸ”¹ KI-Integration

- **Haupt-KI: OpenAI GPT (Ã¼ber API)**
  - Modell: GPT-4-Turbo
  - API-Routen in Next.js fÃ¼r Anfragen an OpenAI
- **Claude (nur fÃ¼r Coding in Cursor)**
  - Nicht in myAE integriert, sondern nur fÃ¼r Entwicklungs-Support in Cursor

## 3ï¸âƒ£ Datenhaltung & Memory Layer

### ğŸ”¹ Environment Variables (Secrets)

- Gespeichert in Vercel â†’ Environment Variables
  - `OPENAI_API_KEY` â†’ API-Key fÃ¼r OpenAI
  - `APP_ENV` â†’ "production" oder "development"

### ğŸ”¹ Kurzzeit-Speicher

- **Upstash Redis** (serverless key-value storage)
  - Speichert temporÃ¤re Kontexte, z. B. Tagesstimmung oder letzte AI-Interaktionen
  - Daten werden nach einer definierten Zeit automatisch gelÃ¶scht

### ğŸ”¹ Langzeit-Speicher

- **Supabase (PostgreSQL)**
  - Speichert persistente Daten, z. B. User-PrÃ¤ferenzen und langfristige Memory-Daten
  - Open-Source Firebase-Alternative mit API-Support

### ğŸ”¹ Semantischer Speicher

- **Pinecone (Vector DB)**
  - Speichert frÃ¼here AI-Interaktionen als Vektoren, um den Kontext Ã¼ber Zeit zu bewahren
  - Nutzt semantische Suche, um frÃ¼here relevante Antworten abzurufen

## 4ï¸âƒ£ API-Architektur

### ğŸ”¹ API-Endpoints (Serverless)

#### ğŸ“ /api/gpt â€“ Kommuniziert mit OpenAI GPT

**POST-Anfrage:**

```json
{
  "prompt": "Wie funktioniert Bitcoin?"
}
```

**Antwort:**

```json
{
  "result": "Bitcoin ist ein dezentrales digitales WÃ¤hrungssystem..."
}
```

- Implementierung in `src/app/api/gpt/route.ts`
- Nutzt `fetch` fÃ¼r OpenAI API-Aufrufe
- Gibt JSON-Response mit `NextResponse.json()` zurÃ¼ck

## 5ï¸âƒ£ User-Interfaces & Erweiterungen

### ğŸ”¹ E-Mail-Service

- **Resend API / Postmark** fÃ¼r tÃ¤gliche Mails
  - Generiert personalisierte Inhalte aus OpenAI API
  - Inhalte basieren auf gespeicherten PrÃ¤ferenzen aus Memory-Layer

### ğŸ”¹ Telegram-Integration (Zukunft)

- MÃ¶glichkeit zur Anbindung eines Telegram-Bots, der myAEs AI-FunktionalitÃ¤t nutzt
- API-Routen kÃ¶nnten Anfragen Ã¼ber Telegram empfangen und Antworten generieren

### ğŸ”¹ Web-Frontend (optional)

- Falls nÃ¶tig, kÃ¶nnte ein Dashboard in Next.js entwickelt werden
- UI zur Verwaltung von Memory-Daten und Personalisierung von AI-Antworten

## 6ï¸âƒ£ Deployment & DevOps

### ğŸ”¹ GitHub â†’ Vercel Deployment-Pipeline

- Code ist in einem privaten GitHub-Repository gespeichert
- Vercel erkennt Commits & baut automatisch neue Versionen
- Branch Protection fÃ¼r main, um ungewollte Ã„nderungen zu verhindern

### ğŸ”¹ CI/CD Automatisierung

- GitHub Actions (spÃ¤ter mÃ¶glich) fÃ¼r Tests & QA vor Deployments
- Logging & Monitoring Ã¼ber Vercel Logs

## ğŸ“Œ Fazit â€“ Zusammenfassung

- Serverless-Backend auf Vercel, optimiert fÃ¼r Skalierung
- Next.js API-Routen mit OpenAI GPT-Integration
- Redis fÃ¼r Kurzzeit-Speicher, PostgreSQL fÃ¼r Langzeit-Daten, Vector DB fÃ¼r semantisches Memory
- Erweiterbar fÃ¼r Telegram-Bots, E-Mail-Automation und Web-Dashboards

Das System kombiniert AI, Memory-Persistenz & Serverless-Optimierung, um ein skalierbares, intelligentes AI-Backend zu bieten.

## ğŸ”– NÃ¤chste Schritte

- Claude kann helfen, die API-Route `/api/gpt` weiter zu optimieren.
- Memory-Integration mit Supabase/Pinecone als nÃ¤chster Meilenstein.
- Erste Live-Tests mit API-Requests und OpenAI-Response-Tuning.

Falls du Anpassungen brauchst oder weitere technische Details mÃ¶chtest, lass es mich wissen! ğŸš€
